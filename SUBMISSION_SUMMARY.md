# Circuit Fingerprint Challenge - Submission Summary

**Team:** [Your Team Name]
**Challenge:** iQuHACK 2026 - Circuit Fingerprint Challenge
**Date:** January 31, 2026

---

## ðŸ“¦ Submission Package

### Files Included

**submission.zip** contains:
- `predict.py` - Main prediction script
- `comprehensive_features.py` - Feature extraction module (62 features)
- `threshold_model.pkl` - Trained threshold classifier (Random Forest)
- `runtime_model.pkl` - Trained runtime regressor (Random Forest)
- `requirements.txt` - Python dependencies

### Run Command

```bash
python predict.py --tasks <TASKS_JSON> --circuits <CIRCUITS_DIR> --id-map <ID_MAP> --out predictions.json
```

---

## ðŸŽ¯ Approach Summary

### Problem

Predict two values for quantum circuit simulations:
1. **Minimum threshold** where fidelity â‰¥ 0.99 (classification)
2. **Forward runtime** for 10,000-shot simulation (regression)

### Solution Strategy

#### 1. Feature Engineering (62 features extracted from QASM)

**Graph Features (Best Predictors):**
- `avg_qubit_degree`: 0.664 correlation with threshold
- `n_unique_edges`: 0.659 correlation with threshold
- Qubit interaction graph metrics

**Circuit Properties:**
- Gate counts (1Q, 2Q gates)
- Circuit size (qubits, total gates)
- Depth estimates
- Gate span metrics

**Pattern Detection:**
- QFT patterns
- Variational patterns (VQE/QAOA)
- Grover patterns

#### 2. Threshold Classification

**Model:** Random Forest Classifier (100 estimators)

**Key Innovation - Conservative Bias:**
- When prediction confidence < 70%, bump to next higher threshold rung
- Prevents catastrophic under-predictions (which score 0 points)
- Trades slight accuracy loss for complete safety

**Performance:**
- Test Accuracy: 85.7%
- **CRITICAL: 0 under-predictions** (0.0%)
- 4 safe over-predictions (14.3%)
- Cross-validation: 94.5% Â± 8.9%

#### 3. Runtime Regression

**Model:** Random Forest Regressor (100 estimators)

**Key Technique:**
- Predict log(runtime) to handle wide variance (1s to 2500s)
- Transform back with exp() for final prediction

**Performance:**
- RÂ² Score: 0.895
- RMSE: 75.39 seconds
- 53.6% predictions within Â±25%
- MAPE: 38.6%

---

## ðŸ“Š Validation Results

### Training Data

- **137 samples** across 36 circuits
- 4 configurations: CPU/GPU Ã— single/double precision
- **Strict fidelity validation:** All thresholds meet sdk_get_fidelity â‰¥ 0.99

### Test Set Performance

**Threshold Classifier (28 test samples):**

| Metric | Value |
|--------|-------|
| Accuracy | 85.7% |
| Exact Predictions | 24/28 (85.7%) |
| Over-predictions | 4/28 (14.3%) - SAFE |
| **Under-predictions** | **0/28 (0.0%)** - âœ… PERFECT |

**Runtime Regressor (28 test samples):**

| Metric | Value |
|--------|-------|
| RÂ² Score | 0.895 |
| RMSE | 75.39s |
| Within Â±25% | 15/28 (53.6%) |
| Within Â±50% | 19/28 (67.9%) |

---

## ðŸ”‘ Key Technical Decisions

### 1. Using sdk_get_fidelity (Not p_return_zero)

We discovered that organizers use `sdk_get_fidelity` for forward run threshold selection, not `p_return_zero`. This critical insight ensured 100% alignment with ground truth labels.

### 2. Conservative Bias Strategy

**Problem:** Predicting threshold too low = automatic zero points
**Solution:** When model confidence < 70%, predict next higher rung
**Result:** Zero under-predictions while maintaining 85.7% accuracy

### 3. Log-Transform for Runtime

Runtime varies from 1s to 2500s (2500Ã—). Log-transform ensures model learns patterns across the entire range effectively.

### 4. Comprehensive Feature Extraction

62 features capture circuit properties without running simulations:
- Graph structure (connectivity, degree distribution)
- Gate composition and ratios
- Depth and complexity metrics
- Pattern detection (QFT, variational, Grover)

---

## ðŸ“ˆ Feature Importance

### Top Features for Threshold Prediction

1. `n_thresholds_tested` (14.8%)
2. `n_h` (6.0%)
3. `avg_gate_span` (5.2%)
4. `crude_depth` (4.7%)
5. `midpoint_cut_crossings` (4.5%)

### Top Features for Runtime Prediction

1. `max_gate_span` (21.5%)
2. `std_gate_span` (14.1%)
3. `avg_gate_span` (9.8%)
4. `forward_peak_rss_mb` (7.8%)
5. `n_h` (7.8%)

---

## âœ… Validation Checklist

- âœ… Models trained on clean, validated data (137 samples)
- âœ… All training thresholds verified with sdk_get_fidelity â‰¥ 0.99
- âœ… Conservative bias prevents under-predictions
- âœ… Test set validation shows zero under-predictions
- âœ… Prediction script tested on holdout format
- âœ… Output format validated with official validator
- âœ… Submission ZIP created with all required files
- âœ… Dependencies documented in requirements.txt

---

## ðŸš€ Strengths

1. **Safety First:** Conservative bias eliminates risk of zero-scoring predictions
2. **Strong Performance:** 85.7% threshold accuracy, RÂ²=0.895 for runtime
3. **Robust Features:** 62 comprehensive features capture circuit properties
4. **Validated Approach:** Extensive testing on holdout format
5. **Clean Code:** Modular design with comprehensive_features.py
6. **Reproducible:** Fixed random seeds, documented dependencies

---

## âš ï¸ Known Limitations

1. **Runtime Outliers:** Some circuits (QFT, portfolioqaoa) have larger errors
2. **Small Training Set:** 137 samples limits model complexity
3. **Class Imbalance:** Thresholds 32 and 256 have few examples (4 and 2 samples)
4. **Conservative Bias Trade-off:** Accuracy reduced from ~100% raw to 85.7% for safety
5. **Metadata Dependency:** Model trained with metadata (n_thresholds_tested, forward_peak_rss_mb) - filled with defaults for holdout

---

## ðŸ”¬ Technical Stack

- **Language:** Python 3.13
- **ML Framework:** scikit-learn 1.3+
- **Data Processing:** pandas, numpy
- **Feature Extraction:** Custom QASM parser
- **Model Persistence:** joblib

---

## ðŸ“ Files for Reference

- `training_data.csv` - Complete training dataset (137 Ã— 72)
- `train_models.py` - Model training script with conservative bias
- `validate_models.py` - Test set validation showing true vs predicted
- `verify_dataset.py` - Validates fidelity requirements
- `build_training_dataset.py` - Dataset construction pipeline
- `PROJECT_STATUS.md` - Quick reference guide

---

## ðŸŽ“ What We Learned

1. **Domain Knowledge Matters:** Understanding sdk_get_fidelity vs p_return_zero was critical
2. **Safety Over Accuracy:** Conservative bias prevents catastrophic failures
3. **Feature Engineering Wins:** Graph features (avg_qubit_degree) beat raw gate counts
4. **Log-Transform Essential:** Wide-range targets need appropriate transformations
5. **Validation is Key:** Test set validation builds confidence before submission

---

## ðŸ“§ Contact

[Your Contact Information]

---

**Submission Ready:** âœ…
**Date:** January 31, 2026
**Version:** 1.0
