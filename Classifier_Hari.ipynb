{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3590207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce872204",
   "metadata": {},
   "source": [
    "**Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7b0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (102, 66) (35, 66)\n",
      "Train classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "Test classes: [np.int64(1), np.int64(2), np.int64(4)]\n",
      "Unique files train: 27 test: 9 overlap: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "\n",
    "# Target for classification is the threshold value\n",
    "y = df[\"min_threshold\"].astype(int).values\n",
    "\n",
    "# Group (so all rows of same circuit stay together)\n",
    "groups = df[\"file\"].astype(str).values\n",
    "\n",
    "# Drop columns we dont want as features\n",
    "drop_cols = [\n",
    "    \"min_threshold\",   # target\n",
    "    \"file\",\n",
    "    \"family\",\n",
    "    \"forward_runtime\", # not for classification, only regression\n",
    "    \"max_fidelity_achieved\",\n",
    "    \"forward_shots\",\n",
    "    \"forward_peak_rss_mb\",\n",
    "    \"n_thresholds_tested\",\n",
    "]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "# X is equal to the whole dataset - dropped columns\n",
    "X = df.drop(columns=drop_cols).copy()\n",
    "\n",
    "# encode categorical columns (backend/precision/etc.)\n",
    "X = pd.get_dummies(X, columns=[c for c in X.columns if X[c].dtype == \"object\" or X[c].dtype == \"str\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Stratified split BY FILE, stratified by n_qubits bucket\n",
    "# ---------------------------\n",
    "\n",
    "# 1) Build a file-level table for stratification\n",
    "file_info = df.groupby(\"file\", as_index=False).agg(\n",
    "    n_qubits=(\"n_qubits\", \"first\")\n",
    ")\n",
    "\n",
    "# Bucketize n_qubits so stratification is stable (avoids classes with only 1 file)\n",
    "file_info[\"qubit_bucket\"] = pd.cut(\n",
    "    file_info[\"n_qubits\"],\n",
    "    bins=[-1, 20, 60, 10**9],\n",
    "    labels=[\"small\", \"medium\", \"large\"]\n",
    ")\n",
    "\n",
    "# 2) Optional: force rare-threshold files into TRAIN (helps avoid \"unseen class 256\")\n",
    "forced_train_files = set(df.loc[df[\"min_threshold\"] == 256, \"file\"].unique())\n",
    "\n",
    "# Split only on remaining files (pool)\n",
    "pool = file_info[~file_info[\"file\"].isin(forced_train_files)].reset_index(drop=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_f_idx, test_f_idx = next(sss.split(pool[\"file\"], pool[\"qubit_bucket\"]))\n",
    "\n",
    "train_files = set(pool.loc[train_f_idx, \"file\"])\n",
    "test_files  = set(pool.loc[test_f_idx, \"file\"])\n",
    "\n",
    "# Add forced files to train\n",
    "train_files |= forced_train_files\n",
    "\n",
    "# Convert file sets -> row indices\n",
    "train_idx = df.index[df[\"file\"].isin(train_files)].to_numpy()\n",
    "test_idx  = df.index[df[\"file\"].isin(test_files)].to_numpy()\n",
    "\n",
    "# Final arrays\n",
    "x_train = X.iloc[train_idx].values.astype(np.float32)\n",
    "x_test  = X.iloc[test_idx].values.astype(np.float32)\n",
    "y_train = y[train_idx]\n",
    "y_test  = y[test_idx]\n",
    "\n",
    "# sanity checks\n",
    "print(\"Shapes:\", x_train.shape, x_test.shape)\n",
    "print(\"Train classes:\", sorted(np.unique(y_train)))\n",
    "print(\"Test classes:\", sorted(np.unique(y_test)))\n",
    "\n",
    "overlap = train_files.intersection(test_files)\n",
    "print(\"Unique files train:\", len(train_files), \"test:\", len(test_files), \"overlap:\", len(overlap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07521eb0",
   "metadata": {},
   "source": [
    "**Metricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b52e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cls_metrics(y_true, y_pred, name=\"model\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    under = np.mean(y_pred < y_true)   # super importante en tu reto\n",
    "    over  = np.mean(y_pred > y_true)\n",
    "\n",
    "    #print(f\"{name}\")\n",
    "    #print(\"  Accuracy:\", round(acc, 4))\n",
    "    #print(\"  Under-rate (pred < true):\", round(float(under), 4))\n",
    "    #print(\"  Over-rate  (pred > true):\", round(float(over), 4))\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57914913-f3e5-4d23-b128-50bbeada9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HOLDOUT TEST: Conservative Strategy (RandomForest Only)\n",
      "======================================================================\n",
      "\n",
      "Holdout files (test set):\n",
      "  - wstate_indep_qiskit_30.qasm (4 samples)\n",
      "  - shor_15_4_indep_qiskit_18.qasm (3 samples)\n",
      "\n",
      "Training samples: 130\n",
      "Test samples: 7\n",
      "\n",
      "Threshold classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "\n",
      "Top 10 features (by RandomForest importance):\n",
      "   1. log_depth                      (0.0374)\n",
      "   2. depth_per_qubit                (0.0365)\n",
      "   3. entanglement_per_qubit         (0.0336)\n",
      "   4. n_h                            (0.0332)\n",
      "   5. degree_squared                 (0.0317)\n",
      "   6. crude_depth                    (0.0300)\n",
      "   7. avg_qubit_degree               (0.0299)\n",
      "   8. n_nonempty_lines               (0.0279)\n",
      "   9. depth_squared                  (0.0275)\n",
      "  10. n_lines                        (0.0273)\n",
      "\n",
      "======================================================================\n",
      "DETAILED RESULTS FOR HOLDOUT TEST SET\n",
      "======================================================================\n",
      "\n",
      "File                                Backend Prec     True   Conf\n",
      "-----------------------------------------------------------------\n",
      "shor_15_4_indep_qiskit_18.qasm      CPU   double      4   0.74\n",
      "shor_15_4_indep_qiskit_18.qasm      GPU   double      4   0.74\n",
      "shor_15_4_indep_qiskit_18.qasm      GPU   single      4   0.74\n",
      "wstate_indep_qiskit_30.qasm         CPU   double      2   0.95\n",
      "wstate_indep_qiskit_30.qasm         CPU   single      2   0.95\n",
      "wstate_indep_qiskit_30.qasm         GPU   double      2   0.95\n",
      "wstate_indep_qiskit_30.qasm         GPU   single      2   0.95\n",
      "\n",
      "======================================================================\n",
      "STRATEGY COMPARISON\n",
      "======================================================================\n",
      "\n",
      "raw:\n",
      "  Score: 4.00/7 = 0.5714\n",
      "  Exact=4, Under=3 [RISK!], Over=0, Bumped=7\n",
      "  Predictions: [1, 1, 1, 2, 2, 2, 2]\n",
      "\n",
      "cons_80:\n",
      "  Score: 4.00/7 = 0.5714\n",
      "  Exact=4, Under=3 [RISK!], Over=0, Bumped=3\n",
      "  Predictions: [2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "cons_70:\n",
      "  Score: 4.00/7 = 0.5714\n",
      "  Exact=4, Under=3 [RISK!], Over=0, Bumped=0\n",
      "  Predictions: [1, 1, 1, 2, 2, 2, 2]\n",
      "\n",
      "cons_60:\n",
      "  Score: 4.00/7 = 0.5714\n",
      "  Exact=4, Under=3 [RISK!], Over=0, Bumped=0\n",
      "  Predictions: [1, 1, 1, 2, 2, 2, 2]\n",
      "\n",
      "always_+1:\n",
      "  Score: 2.00/7 = 0.2857\n",
      "  Exact=0, Under=3 [RISK!], Over=4, Bumped=7\n",
      "  Predictions: [2, 2, 2, 4, 4, 4, 4]\n",
      "\n",
      "always_+2:\n",
      "  Score: 4.00/7 = 0.5714\n",
      "  Exact=3, Under=0 [RISK!], Over=4, Bumped=7\n",
      "  Predictions: [4, 4, 4, 8, 8, 8, 8]\n",
      "\n",
      "======================================================================\n",
      "SUMMARY - Sorted by Underprediction Risk\n",
      "======================================================================\n",
      "Strategy           Score  Exact  Under   Over Risk      \n",
      "-------------------------------------------------------\n",
      "always_+2           4.00      3      0      4 LOW       \n",
      "raw                 4.00      4      3      0 HIGH      \n",
      "cons_80             4.00      4      3      0 HIGH      \n",
      "cons_70             4.00      4      3      0 HIGH      \n",
      "cons_60             4.00      4      3      0 HIGH      \n",
      "always_+1           2.00      0      3      4 HIGH      \n",
      "\n",
      "True values: [np.int64(4), np.int64(4), np.int64(4), np.int64(2), np.int64(2), np.int64(2), np.int64(2)]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HOLDOUT TEST: Conservative 60% Strategy (RandomForest only)\n",
    "# =============================================================================\n",
    "# Train on all data EXCEPT two holdout files, test on those files\n",
    "# Using conservative_60: bump prediction up when confidence < 60%\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. LOAD DATA AND FEATURE ENGINEERING\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create domain-specific features for quantum circuit threshold prediction.\"\"\"\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Interaction features\n",
    "    X['degree_x_qubits'] = X['avg_qubit_degree'] * X['n_qubits']\n",
    "    X['degree_x_depth'] = X['avg_qubit_degree'] * X['crude_depth']\n",
    "    X['degree_x_2q'] = X['avg_qubit_degree'] * X['n_2q_gates']\n",
    "    X['entanglement_complexity'] = X['n_unique_edges'] * X['avg_qubit_degree']\n",
    "    X['entanglement_per_qubit'] = X['n_unique_edges'] / (X['n_qubits'] + 1)\n",
    "    \n",
    "    # Ratio features\n",
    "    X['cx_ratio'] = X['n_cx'] / (X['n_total_gates'] + 1)\n",
    "    X['rotation_ratio'] = X['n_rotation_gates'] / (X['n_total_gates'] + 1)\n",
    "    X['multi_qubit_ratio'] = (X['n_2q_gates'] + X['n_3q_gates']) / (X['n_total_gates'] + 1)\n",
    "    X['gates_per_depth'] = X['n_total_gates'] / (X['crude_depth'] + 1)\n",
    "    X['depth_per_qubit'] = X['crude_depth'] / (X['n_qubits'] + 1)\n",
    "    X['edge_density'] = X['n_unique_edges'] / (X['n_qubits'] * (X['n_qubits'] - 1) / 2 + 1)\n",
    "    X['edge_repetition_ratio'] = X['n_edge_repetitions'] / (X['n_unique_edges'] + 1)\n",
    "    \n",
    "    # Polynomial features\n",
    "    X['degree_squared'] = X['avg_qubit_degree'] ** 2\n",
    "    X['qubits_squared'] = X['n_qubits'] ** 2\n",
    "    X['depth_squared'] = X['crude_depth'] ** 2\n",
    "    X['log_qubits'] = np.log1p(X['n_qubits'])\n",
    "    X['log_depth'] = np.log1p(X['crude_depth'])\n",
    "    X['log_gates'] = np.log1p(X['n_total_gates'])\n",
    "    \n",
    "    # Complexity scores\n",
    "    X['complexity_score'] = X['n_qubits'] * X['crude_depth'] * X['avg_qubit_degree'] / 1000\n",
    "    X['entanglement_burden'] = X['n_2q_gates'] * X['avg_qubit_degree'] / (X['n_qubits'] + 1)\n",
    "    X['sim_difficulty'] = X['n_qubits'] ** 1.5 * X['entanglement_pressure']\n",
    "    \n",
    "    # Pattern features\n",
    "    X['n_patterns'] = (X['has_qft_pattern'] + X['has_iqft_pattern'] + \n",
    "                       X['has_grover_pattern'] + X['has_variational_pattern'] + X['has_ghz_pattern'])\n",
    "    X['variational_complexity'] = X['has_variational_pattern'] * X['n_rotation_gates']\n",
    "    \n",
    "    return X\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. DEFINE HOLDOUT FILES\n",
    "# -----------------------------------------------------------------------------\n",
    "holdout_files = [\n",
    "    \"wstate_indep_qiskit_30.qasm\",\n",
    "    \"shor_15_4_indep_qiskit_18.qasm\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HOLDOUT TEST: Conservative Strategy (RandomForest Only)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Holdout files (test set):\")\n",
    "for f in holdout_files:\n",
    "    n_rows = df[df['file'] == f].shape[0]\n",
    "    print(f\"  - {f} ({n_rows} samples)\")\n",
    "print()\n",
    "\n",
    "# Split into train and test\n",
    "train_mask = ~df['file'].isin(holdout_files)\n",
    "test_mask = df['file'].isin(holdout_files)\n",
    "\n",
    "df_train = df[train_mask].copy()\n",
    "df_test = df[test_mask].copy()\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. PREPARE FEATURES\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train_eng = engineer_features(df_train)\n",
    "X_test_eng = engineer_features(df_test)\n",
    "\n",
    "# Drop non-feature columns\n",
    "drop_cols = [\"min_threshold\", \"file\", \"family\", \"forward_runtime\", \n",
    "             \"max_fidelity_achieved\", \"forward_shots\", \"forward_peak_rss_mb\", \"n_thresholds_tested\"]\n",
    "drop_cols = [c for c in drop_cols if c in X_train_eng.columns]\n",
    "\n",
    "X_train_eng = X_train_eng.drop(columns=drop_cols)\n",
    "X_test_eng = X_test_eng.drop(columns=drop_cols)\n",
    "\n",
    "# One-hot encode categoricals\n",
    "cat_cols = X_train_eng.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "X_train_eng = pd.get_dummies(X_train_eng, columns=cat_cols)\n",
    "X_test_eng = pd.get_dummies(X_test_eng, columns=cat_cols)\n",
    "\n",
    "# Align columns (test may have different dummies)\n",
    "X_test_eng = X_test_eng.reindex(columns=X_train_eng.columns, fill_value=0)\n",
    "\n",
    "# Get labels\n",
    "y_train_raw = df_train[\"min_threshold\"].astype(int).values\n",
    "y_test_raw = df_test[\"min_threshold\"].astype(int).values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"min_threshold\"].astype(int).values)  # Fit on ALL data to know all classes\n",
    "y_train = le.transform(y_train_raw)\n",
    "y_test = le.transform(y_test_raw)\n",
    "\n",
    "threshold_classes = le.classes_\n",
    "print(f\"Threshold classes: {list(threshold_classes)}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. FEATURE SELECTION (Top 10 by RandomForest importance)\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train_arr = X_train_eng.values.astype(np.float32)\n",
    "X_train_arr = np.nan_to_num(X_train_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Use RandomForest for feature importance\n",
    "clf_importance = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "    class_weight='balanced', random_state=42, n_jobs=-1\n",
    ")\n",
    "clf_importance.fit(X_train_arr, y_train)\n",
    "\n",
    "feature_importance = clf_importance.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train_eng.columns.tolist(),\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_k = 10\n",
    "top_features = importance_df.head(top_k)['feature'].tolist()\n",
    "\n",
    "print(f\"Top {top_k} features (by RandomForest importance):\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    imp = importance_df[importance_df['feature'] == feat]['importance'].values[0]\n",
    "    print(f\"  {i:2d}. {feat:<30} ({imp:.4f})\")\n",
    "print()\n",
    "\n",
    "X_train_top = X_train_eng[top_features].values.astype(np.float32)\n",
    "X_test_top = X_test_eng[top_features].values.astype(np.float32)\n",
    "X_train_top = np.nan_to_num(X_train_top, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test_top = np.nan_to_num(X_test_top, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. TRAIN MODEL AND CONSERVATIVE PREDICT\n",
    "# -----------------------------------------------------------------------------\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "    class_weight='balanced', random_state=42, n_jobs=-1\n",
    ")\n",
    "clf.fit(X_train_top, y_train)\n",
    "\n",
    "def conservative_predict(clf, X, confidence_threshold=0.6, bump_steps=1):\n",
    "    \"\"\"Bump up prediction when confidence < threshold\"\"\"\n",
    "    proba = clf.predict_proba(X)\n",
    "    classes = clf.classes_\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    bumped = []\n",
    "    \n",
    "    for p in proba:\n",
    "        max_prob = p.max()\n",
    "        max_class_idx = p.argmax()\n",
    "        \n",
    "        if max_prob < confidence_threshold:\n",
    "            new_idx = min(max_class_idx + bump_steps, len(classes) - 1)\n",
    "            predictions.append(classes[new_idx])\n",
    "            bumped.append(True)\n",
    "        else:\n",
    "            predictions.append(classes[max_class_idx])\n",
    "            bumped.append(False)\n",
    "        confidences.append(max_prob)\n",
    "    \n",
    "    return np.array(predictions), np.array(confidences), np.array(bumped)\n",
    "\n",
    "# Get predictions with different strategies\n",
    "y_pred_raw = clf.predict(X_test_top)\n",
    "\n",
    "# Test multiple confidence thresholds\n",
    "strategies = {\n",
    "    'raw': (1.0, 0),           # No bumping\n",
    "    'cons_80': (0.80, 1),      # Bump if conf < 80%\n",
    "    'cons_70': (0.70, 1),      # Bump if conf < 70%\n",
    "    'cons_60': (0.60, 1),      # Bump if conf < 60%\n",
    "    'always_+1': (1.01, 1),    # Always bump by 1\n",
    "    'always_+2': (1.01, 2),    # Always bump by 2\n",
    "}\n",
    "\n",
    "# Convert test labels\n",
    "y_test_orig = le.inverse_transform(y_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. COMPETITION SCORING\n",
    "# -----------------------------------------------------------------------------\n",
    "def competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculate competition score\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    scores = np.zeros(len(y_true))\n",
    "    scores[y_pred == y_true] = 1.0\n",
    "    over = y_pred > y_true\n",
    "    scores[over] = y_true[over] / y_pred[over]\n",
    "    return scores\n",
    "\n",
    "def get_outcome(true, pred):\n",
    "    if pred == true:\n",
    "        return \"EXACT\"\n",
    "    elif pred < true:\n",
    "        return \"UNDER\"\n",
    "    else:\n",
    "        return \"OVER\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. DISPLAY RESULTS FOR ALL STRATEGIES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"DETAILED RESULTS FOR HOLDOUT TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Get raw predictions with probabilities for display\n",
    "proba = clf.predict_proba(X_test_top)\n",
    "raw_confidences = [p.max() for p in proba]\n",
    "\n",
    "print(f\"{'File':<35} {'Backend':<5} {'Prec':<7} {'True':>5} {'Conf':>6}\")\n",
    "print(\"-\" * 65)\n",
    "for i, (_, row) in enumerate(df_test.iterrows()):\n",
    "    print(f\"{row['file']:<35} {row['backend']:<5} {row['precision']:<7} \"\n",
    "          f\"{y_test_orig[i]:>5} {raw_confidences[i]:>6.2f}\")\n",
    "print()\n",
    "\n",
    "# Evaluate each strategy\n",
    "print(\"=\" * 70)\n",
    "print(\"STRATEGY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for strat_name, (thresh, bump) in strategies.items():\n",
    "    if thresh > 1.0:  # Always bump\n",
    "        y_pred = np.minimum(y_pred_raw + bump, len(le.classes_) - 1)\n",
    "        y_pred_orig = le.inverse_transform(y_pred)\n",
    "        bumped = [True] * len(y_pred)\n",
    "    else:\n",
    "        y_pred, _, bumped = conservative_predict(clf, X_test_top, \n",
    "                                                   confidence_threshold=thresh, \n",
    "                                                   bump_steps=bump)\n",
    "        y_pred_orig = le.inverse_transform(y_pred)\n",
    "    \n",
    "    scores = competition_score(y_test_orig, y_pred_orig)\n",
    "    n = len(y_test_orig)\n",
    "    exact = np.sum(y_pred_orig == y_test_orig)\n",
    "    under = np.sum(y_pred_orig < y_test_orig)\n",
    "    over = np.sum(y_pred_orig > y_test_orig)\n",
    "    n_bumped = sum(bumped)\n",
    "    \n",
    "    results_summary.append({\n",
    "        'strategy': strat_name,\n",
    "        'score': scores.sum(),\n",
    "        'exact': exact,\n",
    "        'under': under,\n",
    "        'over': over,\n",
    "        'bumped': n_bumped\n",
    "    })\n",
    "    \n",
    "    print(f\"{strat_name}:\")\n",
    "    print(f\"  Score: {scores.sum():.2f}/{n} = {scores.mean():.4f}\")\n",
    "    print(f\"  Exact={exact}, Under={under} [RISK!], Over={over}, Bumped={n_bumped}\")\n",
    "    \n",
    "    # Show predictions\n",
    "    preds_str = ', '.join([f\"{p}\" for p in y_pred_orig])\n",
    "    print(f\"  Predictions: [{preds_str}]\")\n",
    "    print()\n",
    "\n",
    "# Summary table sorted by underprediction count\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY - Sorted by Underprediction Risk\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Strategy':<15} {'Score':>8} {'Exact':>6} {'Under':>6} {'Over':>6} {'Risk':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for r in sorted(results_summary, key=lambda x: (x['under'], -x['score'])):\n",
    "    risk = \"LOW\" if r['under'] == 0 else (\"MEDIUM\" if r['under'] <= 1 else \"HIGH\")\n",
    "    print(f\"{r['strategy']:<15} {r['score']:>8.2f} {r['exact']:>6} {r['under']:>6} {r['over']:>6} {risk:<10}\")\n",
    "\n",
    "print()\n",
    "print(\"True values:\", list(y_test_orig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d7bc8d5-f550-4381-90ef-ea335738fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRODUCTION THRESHOLD CLASSIFIER\n",
      "======================================================================\n",
      "\n",
      "Best Hyperparameters:\n",
      "  n_estimators: 368\n",
      "  max_depth: 5\n",
      "  min_samples_split: 4\n",
      "  min_samples_leaf: 1\n",
      "  max_features: log2\n",
      "  criterion: entropy\n",
      "  class_weight: balanced_subsample\n",
      "  bootstrap: False\n",
      "  random_state: 42\n",
      "  n_jobs: -1\n",
      "\n",
      "======================================================================\n",
      "TRAINING FILES\n",
      "======================================================================\n",
      "Total: 31 unique QASM files\n",
      "\n",
      "   1. ae_indep_qiskit_130.qasm                      (threshold= 8, samples=1)\n",
      "   2. ae_indep_qiskit_20.qasm                       (threshold= 1, samples=4)\n",
      "   3. cutbell_n30_k6.qasm                           (threshold= 2, samples=4)\n",
      "   4. dj_indep_qiskit_130.qasm                      (threshold= 1, samples=4)\n",
      "   5. dj_indep_qiskit_15.qasm                       (threshold= 1, samples=4)\n",
      "   6. ghz_indep_qiskit_100.qasm                     (threshold= 2, samples=4)\n",
      "   7. ghz_indep_qiskit_130.qasm                     (threshold= 2, samples=4)\n",
      "   8. ghz_indep_qiskit_15.qasm                      (threshold= 2, samples=4)\n",
      "   9. ghz_indep_qiskit_30.qasm                      (threshold= 2, samples=4)\n",
      "  10. graphstate_indep_qiskit_15.qasm               (threshold= 4, samples=3)\n",
      "  11. groundstate_large_indep_qiskit_14.qasm        (threshold= 8, samples=4)\n",
      "  12. grover-noancilla_indep_qiskit_11.qasm         (threshold= 1, samples=4)\n",
      "  13. grover-noancilla_indep_qiskit_7.qasm          (threshold= 1, samples=4)\n",
      "  14. grover-v-chain_indep_qiskit_17.qasm           (threshold= 1, samples=4)\n",
      "  15. grover-v-chain_indep_qiskit_7.qasm            (threshold= 1, samples=4)\n",
      "  16. portfolioqaoa_indep_qiskit_10.qasm            (threshold= 8, samples=4)\n",
      "  17. portfolioqaoa_indep_qiskit_17.qasm            (threshold=16, samples=4)\n",
      "  18. portfoliovqe_indep_qiskit_10.qasm             (threshold= 8, samples=4)\n",
      "  19. qaoa_indep_qiskit_16.qasm                     (threshold= 1, samples=4)\n",
      "  20. qft_indep_qiskit_130.qasm                     (threshold= 1, samples=4)\n",
      "  21. qft_indep_qiskit_15.qasm                      (threshold= 1, samples=4)\n",
      "  22. qft_indep_qiskit_30.qasm                      (threshold= 1, samples=4)\n",
      "  23. qftentangled_indep_qiskit_15.qasm             (threshold= 2, samples=4)\n",
      "  24. qftentangled_indep_qiskit_30.qasm             (threshold= 2, samples=4)\n",
      "  25. qnn_indep_qiskit_20.qasm                      (threshold=16, samples=4)\n",
      "  26. qpeexact_indep_qiskit_100.qasm                (threshold= 1, samples=4)\n",
      "  27. qpeexact_indep_qiskit_30.qasm                 (threshold= 1, samples=4)\n",
      "  28. twolocalrandom_indep_qiskit_30.qasm           (threshold=64, samples=2)\n",
      "  29. vqe_indep_qiskit_16.qasm                      (threshold= 2, samples=4)\n",
      "  30. wstate_indep_qiskit_130.qasm                  (threshold= 2, samples=4)\n",
      "  31. wstate_indep_qiskit_15.qasm                   (threshold= 2, samples=4)\n",
      "\n",
      "======================================================================\n",
      "TEST/HOLDOUT FILES\n",
      "======================================================================\n",
      "Total: 5 unique QASM files\n",
      "\n",
      "   1. dj_indep_qiskit_30.qasm                       (threshold= 1, samples=4)\n",
      "   2. portfoliovqe_indep_qiskit_18.qasm             (threshold=16, samples=4)\n",
      "   3. pricingcall_indep_qiskit_17.qasm              (threshold= 8, samples=4)\n",
      "   4. shor_15_4_indep_qiskit_18.qasm                (threshold= 4, samples=3)\n",
      "   5. wstate_indep_qiskit_30.qasm                   (threshold= 2, samples=4)\n",
      "\n",
      "======================================================================\n",
      "TRAINING MODEL\n",
      "======================================================================\n",
      "\n",
      "Training samples: 118\n",
      "Feature dimensions: 89\n",
      "Threshold classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "\n",
      "Training RandomForest with tuned hyperparameters...\n",
      "Model trained successfully!\n",
      "\n",
      "======================================================================\n",
      "TESTING ON HOLDOUT FILES\n",
      "======================================================================\n",
      "\n",
      "File                                          Backend Prec     True  Pred   Conf  Score\n",
      "------------------------------------------------------------------------------------------\n",
      "dj_indep_qiskit_30.qasm                       CPU   double      1     1   0.65 ✓ 1.00\n",
      "dj_indep_qiskit_30.qasm                       CPU   single      1     1   0.64 ✓ 1.00\n",
      "dj_indep_qiskit_30.qasm                       GPU   double      1     1   0.65 ✓ 1.00\n",
      "dj_indep_qiskit_30.qasm                       GPU   single      1     1   0.64 ✓ 1.00\n",
      "portfoliovqe_indep_qiskit_18.qasm             CPU   double     16    16   0.72 ✓ 1.00\n",
      "portfoliovqe_indep_qiskit_18.qasm             CPU   single     16    16   0.72 ✓ 1.00\n",
      "portfoliovqe_indep_qiskit_18.qasm             GPU   double     16    16   0.72 ✓ 1.00\n",
      "portfoliovqe_indep_qiskit_18.qasm             GPU   single     16    16   0.72 ✓ 1.00\n",
      "pricingcall_indep_qiskit_17.qasm              CPU   double      8    16   0.56 ↑ 0.50\n",
      "pricingcall_indep_qiskit_17.qasm              CPU   single      8    16   0.56 ↑ 0.50\n",
      "pricingcall_indep_qiskit_17.qasm              GPU   double      8    16   0.56 ↑ 0.50\n",
      "pricingcall_indep_qiskit_17.qasm              GPU   single      8    16   0.56 ↑ 0.50\n",
      "shor_15_4_indep_qiskit_18.qasm                CPU   double      4     1   0.74 ↓ 0.00\n",
      "shor_15_4_indep_qiskit_18.qasm                GPU   double      4     1   0.74 ↓ 0.00\n",
      "shor_15_4_indep_qiskit_18.qasm                GPU   single      4     1   0.75 ↓ 0.00\n",
      "wstate_indep_qiskit_30.qasm                   CPU   double      2     2   0.85 ✓ 1.00\n",
      "wstate_indep_qiskit_30.qasm                   CPU   single      2     2   0.85 ✓ 1.00\n",
      "wstate_indep_qiskit_30.qasm                   GPU   double      2     2   0.85 ✓ 1.00\n",
      "wstate_indep_qiskit_30.qasm                   GPU   single      2     2   0.85 ✓ 1.00\n",
      "\n",
      "Total Score: 14.00 / 19 = 0.7368\n",
      "\n",
      "======================================================================\n",
      "USAGE EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "# Basic prediction\n",
      "result = predict_threshold(\n",
      "    qasm_path=\"circuits/your_circuit.qasm\",\n",
      "    backend=\"GPU\",\n",
      "    precision=\"double\"\n",
      ")\n",
      "print(f\"Predicted threshold: {result['predicted_threshold']}\")\n",
      "print(f\"Confidence: {result['confidence']:.2f}\")\n",
      "\n",
      "# Conservative prediction (bumps up when uncertain)\n",
      "result = predict_threshold(\n",
      "    qasm_path=\"circuits/your_circuit.qasm\",\n",
      "    backend=\"GPU\",\n",
      "    precision=\"double\",\n",
      "    conservative=True,\n",
      "    confidence_threshold=0.6\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRODUCTION DEMO: Threshold Classifier\n",
    "# =============================================================================\n",
    "# Usage: predict_threshold(qasm_path, backend, precision)\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import the feature extractor\n",
    "from comprehensive_features import QASMFeatureExtractor\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. BEST HYPERPARAMETERS (from Optuna tuning - paste yours here!)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Replace with your best params from the Optuna run\n",
    "best_rf_params = {\n",
    "    'n_estimators': 368,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 4,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'log2',\n",
    "    'criterion': 'entropy',\n",
    "    'class_weight': 'balanced_subsample',\n",
    "    'bootstrap': False,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "best_rf_params['random_state'] = 42\n",
    "best_rf_params['n_jobs'] = -1\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PRODUCTION THRESHOLD CLASSIFIER\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in best_rf_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. LOAD TRAINING DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "\n",
    "# Define holdout files for testing\n",
    "holdout_files = [\n",
    "    \"wstate_indep_qiskit_30.qasm\",\n",
    "    \"shor_15_4_indep_qiskit_18.qasm\",\n",
    "    \"pricingcall_indep_qiskit_17.qasm\",\n",
    "    \"portfoliovqe_indep_qiskit_18.qasm\",\n",
    "    \"dj_indep_qiskit_30.qasm\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_mask = ~df['file'].isin(holdout_files)\n",
    "test_mask = df['file'].isin(holdout_files)\n",
    "\n",
    "df_train = df[train_mask].copy()\n",
    "df_test = df[test_mask].copy()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. PRINT TRAINING AND TEST FILES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING FILES\")\n",
    "print(\"=\" * 70)\n",
    "train_files = sorted(df_train['file'].unique())\n",
    "print(f\"Total: {len(train_files)} unique QASM files\\n\")\n",
    "for i, f in enumerate(train_files, 1):\n",
    "    n_samples = len(df_train[df_train['file'] == f])\n",
    "    thresh = df_train[df_train['file'] == f]['min_threshold'].iloc[0]\n",
    "    print(f\"  {i:2d}. {f:<45} (threshold={thresh:>2}, samples={n_samples})\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST/HOLDOUT FILES\")\n",
    "print(\"=\" * 70)\n",
    "test_files = sorted(df_test['file'].unique())\n",
    "print(f\"Total: {len(test_files)} unique QASM files\\n\")\n",
    "for i, f in enumerate(test_files, 1):\n",
    "    n_samples = len(df_test[df_test['file'] == f])\n",
    "    thresh = df_test[df_test['file'] == f]['min_threshold'].iloc[0]\n",
    "    print(f\"  {i:2d}. {f:<45} (threshold={thresh:>2}, samples={n_samples})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. FEATURE ENGINEERING FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create domain-specific features for quantum circuit threshold prediction.\"\"\"\n",
    "    X = df.copy()\n",
    "    X['degree_x_qubits'] = X['avg_qubit_degree'] * X['n_qubits']\n",
    "    X['degree_x_depth'] = X['avg_qubit_degree'] * X['crude_depth']\n",
    "    X['degree_x_2q'] = X['avg_qubit_degree'] * X['n_2q_gates']\n",
    "    X['entanglement_complexity'] = X['n_unique_edges'] * X['avg_qubit_degree']\n",
    "    X['entanglement_per_qubit'] = X['n_unique_edges'] / (X['n_qubits'] + 1)\n",
    "    X['cx_ratio'] = X['n_cx'] / (X['n_total_gates'] + 1)\n",
    "    X['rotation_ratio'] = X['n_rotation_gates'] / (X['n_total_gates'] + 1)\n",
    "    X['multi_qubit_ratio'] = (X['n_2q_gates'] + X['n_3q_gates']) / (X['n_total_gates'] + 1)\n",
    "    X['gates_per_depth'] = X['n_total_gates'] / (X['crude_depth'] + 1)\n",
    "    X['depth_per_qubit'] = X['crude_depth'] / (X['n_qubits'] + 1)\n",
    "    X['edge_density'] = X['n_unique_edges'] / (X['n_qubits'] * (X['n_qubits'] - 1) / 2 + 1)\n",
    "    X['edge_repetition_ratio'] = X['n_edge_repetitions'] / (X['n_unique_edges'] + 1)\n",
    "    X['degree_squared'] = X['avg_qubit_degree'] ** 2\n",
    "    X['qubits_squared'] = X['n_qubits'] ** 2\n",
    "    X['depth_squared'] = X['crude_depth'] ** 2\n",
    "    X['log_qubits'] = np.log1p(X['n_qubits'])\n",
    "    X['log_depth'] = np.log1p(X['crude_depth'])\n",
    "    X['log_gates'] = np.log1p(X['n_total_gates'])\n",
    "    X['complexity_score'] = X['n_qubits'] * X['crude_depth'] * X['avg_qubit_degree'] / 1000\n",
    "    X['entanglement_burden'] = X['n_2q_gates'] * X['avg_qubit_degree'] / (X['n_qubits'] + 1)\n",
    "    X['sim_difficulty'] = X['n_qubits'] ** 1.5 * X['entanglement_pressure']\n",
    "    X['n_patterns'] = (X['has_qft_pattern'] + X['has_iqft_pattern'] + \n",
    "                       X['has_grover_pattern'] + X['has_variational_pattern'] + X['has_ghz_pattern'])\n",
    "    X['variational_complexity'] = X['has_variational_pattern'] * X['n_rotation_gates']\n",
    "    return X\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. PREPARE TRAINING DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Engineer features for training data\n",
    "X_train_eng = engineer_features(df_train)\n",
    "\n",
    "# Columns to drop (not features)\n",
    "drop_cols = [\"min_threshold\", \"file\", \"family\", \"forward_runtime\", \n",
    "             \"max_fidelity_achieved\", \"forward_shots\", \"forward_peak_rss_mb\", \"n_thresholds_tested\"]\n",
    "drop_cols = [c for c in drop_cols if c in X_train_eng.columns]\n",
    "X_train_eng = X_train_eng.drop(columns=drop_cols)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "cat_cols = X_train_eng.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "X_train_eng = pd.get_dummies(X_train_eng, columns=cat_cols)\n",
    "\n",
    "# Store column order for prediction\n",
    "FEATURE_COLUMNS = X_train_eng.columns.tolist()\n",
    "\n",
    "# Prepare arrays\n",
    "X_train = X_train_eng.values.astype(np.float32)\n",
    "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "y_train_raw = df_train[\"min_threshold\"].astype(int).values\n",
    "\n",
    "# Label encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"min_threshold\"].astype(int).values)  # Fit on ALL thresholds\n",
    "y_train = le.transform(y_train_raw)\n",
    "\n",
    "THRESHOLD_CLASSES = le.classes_\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Feature dimensions: {X_train.shape[1]}\")\n",
    "print(f\"Threshold classes: {list(THRESHOLD_CLASSES)}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. TRAIN THE MODEL\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Training RandomForest with tuned hyperparameters...\")\n",
    "clf = RandomForestClassifier(**best_rf_params)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model trained successfully!\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. PREDICTION FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "def predict_threshold(qasm_path, backend, precision, conservative=False, confidence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Predict the optimal threshold for a QASM circuit.\n",
    "    \n",
    "    Args:\n",
    "        qasm_path: Path to the QASM file\n",
    "        backend: 'CPU' or 'GPU'\n",
    "        precision: 'single' or 'double'\n",
    "        conservative: If True, bump up prediction when confidence is low\n",
    "        confidence_threshold: Threshold for conservative prediction (default 0.6)\n",
    "    \n",
    "    Returns:\n",
    "        dict with prediction, confidence, and probabilities\n",
    "    \"\"\"\n",
    "    # Extract features from QASM file\n",
    "    extractor = QASMFeatureExtractor(qasm_path)\n",
    "    circuit_features = extractor.extract_all()\n",
    "    \n",
    "    # Create a DataFrame row with circuit features + config\n",
    "    row = circuit_features.copy()\n",
    "    row['backend'] = backend\n",
    "    row['precision'] = precision\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    input_df = pd.DataFrame([row])\n",
    "    \n",
    "    # Engineer additional features\n",
    "    input_eng = engineer_features(input_df)\n",
    "    \n",
    "    # Drop non-feature columns\n",
    "    for col in drop_cols:\n",
    "        if col in input_eng.columns:\n",
    "            input_eng = input_eng.drop(columns=[col])\n",
    "    \n",
    "    # One-hot encode\n",
    "    cat_cols_input = input_eng.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    input_eng = pd.get_dummies(input_eng, columns=cat_cols_input)\n",
    "    \n",
    "    # Align with training columns\n",
    "    input_eng = input_eng.reindex(columns=FEATURE_COLUMNS, fill_value=0)\n",
    "    \n",
    "    # Prepare array\n",
    "    X_input = input_eng.values.astype(np.float32)\n",
    "    X_input = np.nan_to_num(X_input, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Get prediction and probabilities\n",
    "    proba = clf.predict_proba(X_input)[0]\n",
    "    pred_encoded = clf.predict(X_input)[0]\n",
    "    confidence = proba.max()\n",
    "    \n",
    "    # Conservative prediction: bump up if not confident\n",
    "    if conservative and confidence < confidence_threshold:\n",
    "        # Bump up by 1 class\n",
    "        new_idx = min(pred_encoded + 1, len(THRESHOLD_CLASSES) - 1)\n",
    "        pred_encoded = new_idx\n",
    "    \n",
    "    pred_threshold = le.inverse_transform([pred_encoded])[0]\n",
    "    \n",
    "    # Build probability dict\n",
    "    prob_dict = {int(THRESHOLD_CLASSES[i]): float(proba[i]) for i in range(len(THRESHOLD_CLASSES))}\n",
    "    \n",
    "    return {\n",
    "        'predicted_threshold': int(pred_threshold),\n",
    "        'confidence': float(confidence),\n",
    "        'probabilities': prob_dict,\n",
    "        'conservative_mode': conservative\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8. TEST ON HOLDOUT FILES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING ON HOLDOUT FILES\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    if y_pred == y_true:\n",
    "        return 1.0\n",
    "    elif y_pred > y_true:\n",
    "        return y_true / y_pred\n",
    "    else:\n",
    "        return 0.0  # Underprediction\n",
    "\n",
    "circuits_dir = Path(\"circuits\")\n",
    "\n",
    "print(f\"{'File':<45} {'Backend':<5} {'Prec':<7} {'True':>5} {'Pred':>5} {'Conf':>6} {'Score':>6}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "total_score = 0\n",
    "total_samples = 0\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    qasm_path = circuits_dir / row['file']\n",
    "    \n",
    "    result = predict_threshold(\n",
    "        qasm_path=qasm_path,\n",
    "        backend=row['backend'],\n",
    "        precision=row['precision'],\n",
    "        conservative=False\n",
    "    )\n",
    "    \n",
    "    true_thresh = int(row['min_threshold'])\n",
    "    pred_thresh = result['predicted_threshold']\n",
    "    conf = result['confidence']\n",
    "    score = competition_score(true_thresh, pred_thresh)\n",
    "    \n",
    "    total_score += score\n",
    "    total_samples += 1\n",
    "    \n",
    "    status = \"✓\" if pred_thresh == true_thresh else (\"↓\" if pred_thresh < true_thresh else \"↑\")\n",
    "    print(f\"{row['file']:<45} {row['backend']:<5} {row['precision']:<7} \"\n",
    "          f\"{true_thresh:>5} {pred_thresh:>5} {conf:>6.2f} {status}{score:>5.2f}\")\n",
    "\n",
    "print()\n",
    "print(f\"Total Score: {total_score:.2f} / {total_samples} = {total_score/total_samples:.4f}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9. USAGE EXAMPLE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\" * 70)\n",
    "print(\"USAGE EXAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print('# Basic prediction')\n",
    "print('result = predict_threshold(')\n",
    "print('    qasm_path=\"circuits/your_circuit.qasm\",')\n",
    "print('    backend=\"GPU\",')\n",
    "print('    precision=\"double\"')\n",
    "print(')')\n",
    "print('print(f\"Predicted threshold: {result[\\'predicted_threshold\\']}\")')\n",
    "print('print(f\"Confidence: {result[\\'confidence\\']:.2f}\")')\n",
    "print()\n",
    "print('# Conservative prediction (bumps up when uncertain)')\n",
    "print('result = predict_threshold(')\n",
    "print('    qasm_path=\"circuits/your_circuit.qasm\",')\n",
    "print('    backend=\"GPU\",')\n",
    "print('    precision=\"double\",')\n",
    "print('    conservative=True,')\n",
    "print('    confidence_threshold=0.6')\n",
    "print(')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff2c94-c537-4112-9e9f-04621de36c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservative prediction (bumps up when uncertain)\n",
    "result1 = predict_threshold(\n",
    "    qasm_path=\"test_circuits/graphstate_indep_qiskit_30.qasm\",\n",
    "    backend=\"CPU\",\n",
    "    precision=\"double\",\n",
    "    conservative=True,\n",
    "    confidence_threshold=0.6\n",
    ")\n",
    "\n",
    "result2 = predict_threshold(\n",
    "    qasm_path=\"test_circuits/pricingcall_indep_qiskit_25.qasm\",\n",
    "    backend=\"CPU\",\n",
    "    precision=\"double\",\n",
    "    conservative=True,\n",
    "    confidence_threshold=0.6\n",
    ")\n",
    "\n",
    "result3 = predict_threshold(\n",
    "    qasm_path=\"test_circuits/qftentangled_indep_qiskit_130.qasm\",\n",
    "    backend=\"CPU\",\n",
    "    precision=\"double\",\n",
    "    conservative=True,\n",
    "    confidence_threshold=0.6\n",
    ")\n",
    "\n",
    "result4 = predict_threshold(\n",
    "    qasm_path=\"test_circuits/qnn_indep_qiskit_30.qasm\",\n",
    "    backend=\"CPU\",\n",
    "    precision=\"double\",\n",
    "    conservative=True,\n",
    "    confidence_threshold=0.6\n",
    ")\n",
    "\n",
    "result5 = predict_threshold(\n",
    "    qasm_path=\"test_circuits/shor_9_4_indep_qiskit_18.qasm\",\n",
    "    backend=\"CPU\",\n",
    "    precision=\"double\",\n",
    "    conservative=True,\n",
    "    confidence_threshold=0.6\n",
    ")\n",
    "\n",
    "print(f\"Predicted threshold: {result['predicted_threshold']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e201e-1645-4c41-92e3-8f9fc31415e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
