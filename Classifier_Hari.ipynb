{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3590207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce872204",
   "metadata": {},
   "source": [
    "**Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f7b0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (102, 66) (35, 66)\n",
      "Train classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "Test classes: [np.int64(1), np.int64(2), np.int64(4)]\n",
      "Unique files train: 27 test: 9 overlap: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "\n",
    "# Target for classification is the threshold value\n",
    "y = df[\"min_threshold\"].astype(int).values\n",
    "\n",
    "# Group (so all rows of same circuit stay together)\n",
    "groups = df[\"file\"].astype(str).values\n",
    "\n",
    "# Drop columns we dont want as features\n",
    "drop_cols = [\n",
    "    \"min_threshold\",   # target\n",
    "    \"file\",\n",
    "    \"family\",\n",
    "    \"forward_runtime\", # not for classification, only regression\n",
    "    \"max_fidelity_achieved\",\n",
    "    \"forward_shots\",\n",
    "    \"forward_peak_rss_mb\",\n",
    "    \"n_thresholds_tested\",\n",
    "]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "# X is equal to the whole dataset - dropped columns\n",
    "X = df.drop(columns=drop_cols).copy()\n",
    "\n",
    "# encode categorical columns (backend/precision/etc.)\n",
    "X = pd.get_dummies(X, columns=[c for c in X.columns if X[c].dtype == \"object\" or X[c].dtype == \"str\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Stratified split BY FILE, stratified by n_qubits bucket\n",
    "# ---------------------------\n",
    "\n",
    "# 1) Build a file-level table for stratification\n",
    "file_info = df.groupby(\"file\", as_index=False).agg(\n",
    "    n_qubits=(\"n_qubits\", \"first\")\n",
    ")\n",
    "\n",
    "# Bucketize n_qubits so stratification is stable (avoids classes with only 1 file)\n",
    "file_info[\"qubit_bucket\"] = pd.cut(\n",
    "    file_info[\"n_qubits\"],\n",
    "    bins=[-1, 20, 60, 10**9],\n",
    "    labels=[\"small\", \"medium\", \"large\"]\n",
    ")\n",
    "\n",
    "# 2) Optional: force rare-threshold files into TRAIN (helps avoid \"unseen class 256\")\n",
    "forced_train_files = set(df.loc[df[\"min_threshold\"] == 256, \"file\"].unique())\n",
    "\n",
    "# Split only on remaining files (pool)\n",
    "pool = file_info[~file_info[\"file\"].isin(forced_train_files)].reset_index(drop=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_f_idx, test_f_idx = next(sss.split(pool[\"file\"], pool[\"qubit_bucket\"]))\n",
    "\n",
    "train_files = set(pool.loc[train_f_idx, \"file\"])\n",
    "test_files  = set(pool.loc[test_f_idx, \"file\"])\n",
    "\n",
    "# Add forced files to train\n",
    "train_files |= forced_train_files\n",
    "\n",
    "# Convert file sets -> row indices\n",
    "train_idx = df.index[df[\"file\"].isin(train_files)].to_numpy()\n",
    "test_idx  = df.index[df[\"file\"].isin(test_files)].to_numpy()\n",
    "\n",
    "# Final arrays\n",
    "x_train = X.iloc[train_idx].values.astype(np.float32)\n",
    "x_test  = X.iloc[test_idx].values.astype(np.float32)\n",
    "y_train = y[train_idx]\n",
    "y_test  = y[test_idx]\n",
    "\n",
    "# sanity checks\n",
    "print(\"Shapes:\", x_train.shape, x_test.shape)\n",
    "print(\"Train classes:\", sorted(np.unique(y_train)))\n",
    "print(\"Test classes:\", sorted(np.unique(y_test)))\n",
    "\n",
    "overlap = train_files.intersection(test_files)\n",
    "print(\"Unique files train:\", len(train_files), \"test:\", len(test_files), \"overlap:\", len(overlap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07521eb0",
   "metadata": {},
   "source": [
    "**Metricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44b52e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cls_metrics(y_true, y_pred, name=\"model\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    under = np.mean(y_pred < y_true)   # super importante en tu reto\n",
    "    over  = np.mean(y_pred > y_true)\n",
    "\n",
    "    #print(f\"{name}\")\n",
    "    #print(\"  Accuracy:\", round(acc, 4))\n",
    "    #print(\"  Under-rate (pred < true):\", round(float(under), 4))\n",
    "    #print(\"  Over-rate  (pred > true):\", round(float(over), 4))\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab7f0822-bdd4-4e42-842f-51e36c8622b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 137 samples, 66 features\n",
      "Files: 36 unique circuits (~3.8 samples each)\n",
      "Classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "\n",
      "Using StratifiedGroupKFold with 2 splits (grouped by file)\n",
      "\n",
      "Fold 1: Acc=0.5352, Test classes=[np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16)], n_test=71, file_overlap=0\n",
      "Fold 2: Acc=0.5152, Test classes=[np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)], n_test=66, file_overlap=0\n",
      "\n",
      "LinearSVC (PROPER GroupKFold):\n",
      "  Mean Accuracy: 0.5252 Â± 0.0100\n",
      "\n",
      "Confusion Matrix:\n",
      "Classes: [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "[[46  7  0  1  0  0]\n",
      " [ 6 26  0  2 12  0]\n",
      " [ 3  3  0  0  0  0]\n",
      " [ 0  8  8  0  1  0]\n",
      " [ 0  4  4  0  0  4]\n",
      " [ 0  0  0  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "# Load fresh data to ensure we have everything\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "y = df[\"min_threshold\"].astype(int).values\n",
    "groups = df[\"file\"].astype(str).values  # CRITICAL: group by file to prevent leakage\n",
    "\n",
    "drop_cols = [\"min_threshold\", \"file\", \"family\", \"forward_runtime\", \n",
    "             \"max_fidelity_achieved\", \"forward_shots\", \"forward_peak_rss_mb\", \"n_thresholds_tested\"]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "X = df.drop(columns=drop_cols).copy()\n",
    "X = pd.get_dummies(X, columns=X.select_dtypes(exclude=[np.number]).columns.tolist())\n",
    "X_arr = X.values.astype(np.float32)\n",
    "\n",
    "print(f\"Data: {X_arr.shape[0]} samples, {X_arr.shape[1]} features\")\n",
    "print(f\"Files: {len(np.unique(groups))} unique circuits (~{len(y)/len(np.unique(groups)):.1f} samples each)\")\n",
    "print(f\"Classes: {sorted(np.unique(y))}\")\n",
    "print()\n",
    "\n",
    "# Pipeline with scaling (important for SVM)\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42, max_iter=5000)),\n",
    "])\n",
    "\n",
    "# CORRECT: StratifiedGroupKFold - keeps all samples from same file together\n",
    "min_class_count = min(np.bincount(y)[np.bincount(y) > 0])\n",
    "n_splits = min(3, min_class_count)  # Can't have more splits than smallest class\n",
    "\n",
    "print(f\"Using StratifiedGroupKFold with {n_splits} splits (grouped by file)\")\n",
    "print()\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(sgkf.split(X_arr, y, groups)):\n",
    "        X_train, X_test = X_arr[train_idx], X_arr[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Check no file overlap (sanity check)\n",
    "        train_files = set(groups[train_idx])\n",
    "        test_files = set(groups[test_idx])\n",
    "        overlap = train_files & test_files\n",
    "        \n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        fold_scores.append(acc)\n",
    "        all_true.extend(y_test)\n",
    "        all_pred.extend(y_pred)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1}: Acc={acc:.4f}, Test classes={sorted(np.unique(y_test))}, \"\n",
    "              f\"n_test={len(y_test)}, file_overlap={len(overlap)}\")\n",
    "\n",
    "print()\n",
    "print(f\"LinearSVC (PROPER GroupKFold):\")\n",
    "print(f\"  Mean Accuracy: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "classes = sorted(np.unique(y))\n",
    "cm = confusion_matrix(all_true, all_pred, labels=classes)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"Classes: {classes}\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wyow1adpu9f",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create domain-specific features to improve model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5zvqu3h0i8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 64\n",
      "Engineered features: 89\n",
      "New features added: 25\n",
      "\n",
      "New features correlation with target:\n",
      "  degree_x_qubits               : +0.747\n",
      "  degree_x_depth                : -0.074\n",
      "  degree_x_2q                   : -0.059\n",
      "  entanglement_complexity       : +0.928\n",
      "  entanglement_per_qubit        : +0.757\n",
      "  cx_ratio                      : +0.144\n",
      "  rotation_ratio                : +0.046\n",
      "  multi_qubit_ratio             : -0.013\n",
      "  gates_per_depth               : -0.094\n",
      "  depth_per_qubit               : -0.091\n",
      "  edge_density                  : +0.471\n",
      "  edge_repetition_ratio         : -0.102\n",
      "  degree_squared                : +0.897\n",
      "  qubits_squared                : -0.146\n",
      "  depth_squared                 : -0.086\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"training_data_75.csv\")\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create domain-specific features for quantum circuit threshold prediction.\"\"\"\n",
    "    X = df.copy()\n",
    "    \n",
    "    # ============================================\n",
    "    # 1. INTERACTION FEATURES (top correlated features combined)\n",
    "    # ============================================\n",
    "    \n",
    "    # Qubit degree interactions (avg_qubit_degree is top predictor)\n",
    "    X['degree_x_qubits'] = X['avg_qubit_degree'] * X['n_qubits']\n",
    "    X['degree_x_depth'] = X['avg_qubit_degree'] * X['crude_depth']\n",
    "    X['degree_x_2q'] = X['avg_qubit_degree'] * X['n_2q_gates']\n",
    "    \n",
    "    # Entanglement complexity\n",
    "    X['entanglement_complexity'] = X['n_unique_edges'] * X['avg_qubit_degree']\n",
    "    X['entanglement_per_qubit'] = X['n_unique_edges'] / (X['n_qubits'] + 1)\n",
    "    \n",
    "    # ============================================\n",
    "    # 2. RATIO FEATURES (relationships between properties)\n",
    "    # ============================================\n",
    "    \n",
    "    # Gate composition ratios\n",
    "    X['cx_ratio'] = X['n_cx'] / (X['n_total_gates'] + 1)\n",
    "    X['rotation_ratio'] = X['n_rotation_gates'] / (X['n_total_gates'] + 1)\n",
    "    X['multi_qubit_ratio'] = (X['n_2q_gates'] + X['n_3q_gates']) / (X['n_total_gates'] + 1)\n",
    "    \n",
    "    # Depth-related ratios\n",
    "    X['gates_per_depth'] = X['n_total_gates'] / (X['crude_depth'] + 1)\n",
    "    X['depth_per_qubit'] = X['crude_depth'] / (X['n_qubits'] + 1)\n",
    "    \n",
    "    # Connectivity ratios\n",
    "    X['edge_density'] = X['n_unique_edges'] / (X['n_qubits'] * (X['n_qubits'] - 1) / 2 + 1)\n",
    "    X['edge_repetition_ratio'] = X['n_edge_repetitions'] / (X['n_unique_edges'] + 1)\n",
    "    \n",
    "    # ============================================\n",
    "    # 3. POLYNOMIAL FEATURES (non-linear relationships)\n",
    "    # ============================================\n",
    "    \n",
    "    X['degree_squared'] = X['avg_qubit_degree'] ** 2\n",
    "    X['qubits_squared'] = X['n_qubits'] ** 2\n",
    "    X['depth_squared'] = X['crude_depth'] ** 2\n",
    "    X['log_qubits'] = np.log1p(X['n_qubits'])\n",
    "    X['log_depth'] = np.log1p(X['crude_depth'])\n",
    "    X['log_gates'] = np.log1p(X['n_total_gates'])\n",
    "    \n",
    "    # ============================================\n",
    "    # 4. CIRCUIT COMPLEXITY SCORES\n",
    "    # ============================================\n",
    "    \n",
    "    # Overall complexity score\n",
    "    X['complexity_score'] = (\n",
    "        X['n_qubits'] * X['crude_depth'] * X['avg_qubit_degree'] / 1000\n",
    "    )\n",
    "    \n",
    "    # Entanglement burden\n",
    "    X['entanglement_burden'] = (\n",
    "        X['n_2q_gates'] * X['avg_qubit_degree'] / (X['n_qubits'] + 1)\n",
    "    )\n",
    "    \n",
    "    # Simulation difficulty proxy\n",
    "    X['sim_difficulty'] = (\n",
    "        X['n_qubits'] ** 1.5 * X['entanglement_pressure']\n",
    "    )\n",
    "    \n",
    "    # ============================================\n",
    "    # 5. PATTERN-BASED FEATURES\n",
    "    # ============================================\n",
    "    \n",
    "    # Combined pattern indicator\n",
    "    X['n_patterns'] = (\n",
    "        X['has_qft_pattern'] + X['has_iqft_pattern'] + \n",
    "        X['has_grover_pattern'] + X['has_variational_pattern'] + X['has_ghz_pattern']\n",
    "    )\n",
    "    \n",
    "    # Variational circuit complexity\n",
    "    X['variational_complexity'] = X['has_variational_pattern'] * X['n_rotation_gates']\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Apply feature engineering\n",
    "X_eng = engineer_features(df)\n",
    "\n",
    "# Drop non-feature columns\n",
    "drop_cols = [\"min_threshold\", \"file\", \"family\", \"forward_runtime\", \n",
    "             \"max_fidelity_achieved\", \"forward_shots\", \"forward_peak_rss_mb\", \"n_thresholds_tested\"]\n",
    "drop_cols = [c for c in drop_cols if c in X_eng.columns]\n",
    "X_eng = X_eng.drop(columns=drop_cols)\n",
    "\n",
    "# One-hot encode categoricals\n",
    "cat_cols = X_eng.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "X_eng = pd.get_dummies(X_eng, columns=cat_cols)\n",
    "\n",
    "print(f\"Original features: 64\")\n",
    "print(f\"Engineered features: {X_eng.shape[1]}\")\n",
    "print(f\"New features added: {X_eng.shape[1] - 64}\")\n",
    "print()\n",
    "\n",
    "# Show new feature correlations\n",
    "y = df[\"min_threshold\"].values\n",
    "new_feat_cols = [c for c in X_eng.columns if c not in df.columns]\n",
    "print(\"New features correlation with target:\")\n",
    "for col in new_feat_cols[:15]:\n",
    "    if col in X_eng.columns:\n",
    "        corr = np.corrcoef(X_eng[col].values, y)[0, 1]\n",
    "        print(f\"  {col:30s}: {corr:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2atofagwusr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {np.int64(1): 0, np.int64(2): 1, np.int64(4): 2, np.int64(8): 3, np.int64(16): 4, np.int64(64): 5}\n",
      "\n",
      "Evaluating models with 89 engineered features...\n",
      "\n",
      "  CatBoost                 : 0.5467 Â± 0.1805\n",
      "  XGBoost                  : 0.4840 Â± 0.0615\n",
      "  LightGBM                 : 0.5079 Â± 0.0837\n",
      "  HistGradientBoosting     : 0.5425 Â± 0.0636\n",
      "  RandomForest             : 0.7200 Â± 0.1285\n",
      "\n",
      "==================================================\n",
      "RANKED RESULTS (with engineered features):\n",
      "==================================================\n",
      "ðŸ‘‘ RandomForest             : 0.7200 Â± 0.1285\n",
      "   CatBoost                 : 0.5467 Â± 0.1805\n",
      "   HistGradientBoosting     : 0.5425 Â± 0.0636\n",
      "   LightGBM                 : 0.5079 Â± 0.0837\n",
      "   XGBoost                  : 0.4840 Â± 0.0615\n",
      "\n",
      "Baseline (CatBoost without engineering): ~0.6566\n",
      "Best improvement: +6.3%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with engineered features - Compare multiple models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "y_raw = df[\"min_threshold\"].astype(int).values\n",
    "groups = df[\"file\"].astype(str).values\n",
    "X_arr = X_eng.values.astype(np.float32)\n",
    "\n",
    "# Handle any NaN/inf from division\n",
    "X_arr = np.nan_to_num(X_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Encode labels for XGBoost (needs 0, 1, 2, ... not 1, 2, 4, 8, ...)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "print(f\"Label mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "print()\n",
    "\n",
    "min_class = min(np.bincount(y)[np.bincount(y) > 0])\n",
    "n_splits = min(3, min_class)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Models to compare\n",
    "models = {\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        iterations=500, depth=6, learning_rate=0.05,\n",
    "        random_seed=42, verbose=False\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "        random_state=42, verbosity=0\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "        random_state=42, verbose=-1\n",
    "    ),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier(\n",
    "        max_iter=500, max_depth=6, learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "        class_weight='balanced', random_state=42, n_jobs=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(f\"Evaluating models with {X_arr.shape[1]} engineered features...\")\n",
    "print()\n",
    "\n",
    "results = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    for name, clf in models.items():\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(sgkf.split(X_arr, y, groups)):\n",
    "            # Clone the model\n",
    "            clf_fold = clf.__class__(**clf.get_params())\n",
    "            clf_fold.fit(X_arr[train_idx], y[train_idx])\n",
    "            y_pred = clf_fold.predict(X_arr[test_idx])\n",
    "            \n",
    "            acc = accuracy_score(y[test_idx], y_pred)\n",
    "            fold_scores.append(acc)\n",
    "        \n",
    "        mean_acc = np.mean(fold_scores)\n",
    "        std_acc = np.std(fold_scores)\n",
    "        results[name] = {\"mean\": mean_acc, \"std\": std_acc, \"folds\": fold_scores}\n",
    "        print(f\"  {name:25s}: {mean_acc:.4f} Â± {std_acc:.4f}\")\n",
    "\n",
    "# Sort by accuracy\n",
    "print()\n",
    "print(\"=\" * 50)\n",
    "print(\"RANKED RESULTS (with engineered features):\")\n",
    "print(\"=\" * 50)\n",
    "for name, res in sorted(results.items(), key=lambda x: -x[1][\"mean\"]):\n",
    "    marker = \"ðŸ‘‘\" if res[\"mean\"] == max(r[\"mean\"] for r in results.values()) else \"  \"\n",
    "    print(f\"{marker} {name:25s}: {res['mean']:.4f} Â± {res['std']:.4f}\")\n",
    "\n",
    "print()\n",
    "print(f\"Baseline (CatBoost without engineering): ~0.6566\")\n",
    "best_name = max(results.items(), key=lambda x: x[1][\"mean\"])[0]\n",
    "best_acc = results[best_name][\"mean\"]\n",
    "print(f\"Best improvement: {(best_acc - 0.6566)*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "buvdl64i5om",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most important features:\n",
      "  n_h                                : 7.83\n",
      "  avg_gate_span                      : 6.95\n",
      "  cx_ratio                           : 6.12\n",
      "  n_cx                               : 4.72\n",
      "  n_u2                               : 4.43\n",
      "  crude_depth                        : 4.12\n",
      "  std_gate_span                      : 3.20\n",
      "  ratio_1q_gates                     : 2.90\n",
      "  1q_gates_per_qubit                 : 2.83\n",
      "  depth_squared                      : 2.38\n",
      "  gates_per_layer_estimate           : 2.17\n",
      "  entanglement_per_qubit             : 2.15\n",
      "  midpoint_cut_crossings             : 2.09\n",
      "  circuit_density                    : 1.92\n",
      "  n_edge_repetitions                 : 1.90\n",
      "  qubits_squared                     : 1.78\n",
      "  degree_squared                     : 1.74\n",
      "  qubit_degree_std                   : 1.66\n",
      "  log_qubits                         : 1.66\n",
      "  n_qubits                           : 1.55\n",
      "\n",
      "Feature selection results:\n",
      "  Top 10 features: 0.7439 Â± 0.0166\n",
      "  Top 20 features: 0.6876 Â± 0.0397\n",
      "  Top 30 features: 0.5186 Â± 0.2087\n",
      "  Top 40 features: 0.5770 Â± 0.2108\n"
     ]
    }
   ],
   "source": [
    "# Try feature selection - keep only the most important features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "# Train a CatBoost model to get feature importances\n",
    "clf_importance = CatBoostClassifier(\n",
    "    iterations=500, depth=6, learning_rate=0.05,\n",
    "    random_seed=42, verbose=False\n",
    ")\n",
    "clf_importance.fit(X_arr, y)\n",
    "\n",
    "feature_importance = clf_importance.get_feature_importance()\n",
    "feature_names = X_eng.columns.tolist()\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "for idx, row in importance_df.head(20).iterrows():\n",
    "    print(f\"  {row['feature']:35s}: {row['importance']:.2f}\")\n",
    "\n",
    "# Try with only top K features\n",
    "print()\n",
    "print(\"Feature selection results:\")\n",
    "for k in [10, 20, 30, 40]:\n",
    "    top_features = importance_df.head(k)['feature'].tolist()\n",
    "    X_selected = X_eng[top_features].values.astype(np.float32)\n",
    "    X_selected = np.nan_to_num(X_selected, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    fold_scores_sel = []\n",
    "    for train_idx, test_idx in sgkf.split(X_selected, y, groups):\n",
    "        clf_sel = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.05, random_seed=42, verbose=False)\n",
    "        clf_sel.fit(X_selected[train_idx], y[train_idx])\n",
    "        y_pred = clf_sel.predict(X_selected[test_idx])\n",
    "        fold_scores_sel.append(accuracy_score(y[test_idx], y_pred))\n",
    "    \n",
    "    print(f\"  Top {k} features: {np.mean(fold_scores_sel):.4f} Â± {np.std(fold_scores_sel):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "py25767ha8h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features:\n",
      "   1. n_h\n",
      "   2. avg_gate_span\n",
      "   3. cx_ratio\n",
      "   4. n_cx\n",
      "   5. n_u2\n",
      "   6. crude_depth\n",
      "   7. std_gate_span\n",
      "   8. ratio_1q_gates\n",
      "   9. 1q_gates_per_qubit\n",
      "  10. depth_squared\n",
      "\n",
      "Running 2-fold StratifiedGroupKFold (grouped by file)...\n",
      "\n",
      "  Fold 1: Acc=0.7042, n_test=71, file_overlap=0, classes=[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
      "  Fold 2: Acc=0.6667, n_test=66, file_overlap=0, classes=[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "\n",
      "============================================================\n",
      "RandomForest + Top 10 Features - FINAL RESULTS\n",
      "============================================================\n",
      "  Mean Accuracy: 0.6854 Â± 0.0188\n",
      "  Per-fold: [0.7042, 0.6667]\n",
      "\n",
      "  Baseline (CatBoost, all features): ~0.6566\n",
      "  Improvement: +2.9%\n",
      "\n",
      "Confusion Matrix:\n",
      "Classes (encoded): [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "Classes (original): [np.int64(1), np.int64(2), np.int64(4), np.int64(8), np.int64(16), np.int64(64)]\n",
      "[[50  0  0  4  0  0]\n",
      " [ 6 36  4  0  0  0]\n",
      " [ 3  0  0  3  0  0]\n",
      " [ 5  4  0  8  0  0]\n",
      " [ 0  0  0  8  0  4]\n",
      " [ 0  0  0  2  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.93      0.85        54\n",
      "           2       0.90      0.78      0.84        46\n",
      "           4       0.00      0.00      0.00         6\n",
      "           8       0.32      0.47      0.38        17\n",
      "          16       0.00      0.00      0.00        12\n",
      "          64       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.69       137\n",
      "   macro avg       0.33      0.36      0.34       137\n",
      "weighted avg       0.65      0.69      0.66       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hari/CODE/python/2026-Quantum-Rings/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/hari/CODE/python/2026-Quantum-Rings/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/hari/CODE/python/2026-Quantum-Rings/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Proper K-Fold evaluation of RandomForest with top 10 features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Get top 10 features by importance\n",
    "top_k = 10\n",
    "top_features = importance_df.head(top_k)['feature'].tolist()\n",
    "X_top = X_eng[top_features].values.astype(np.float32)\n",
    "X_top = np.nan_to_num(X_top, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"Top {top_k} features:\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "print()\n",
    "\n",
    "# Use maximum possible splits based on smallest class\n",
    "min_class = min(np.bincount(y)[np.bincount(y) > 0])\n",
    "n_splits = min(5, min_class)  # Try to get more folds if possible\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "print(f\"Running {n_splits}-fold StratifiedGroupKFold (grouped by file)...\")\n",
    "print()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(sgkf.split(X_top, y, groups)):\n",
    "    # Verify no file overlap\n",
    "    train_files = set(groups[train_idx])\n",
    "    test_files = set(groups[test_idx])\n",
    "    overlap = len(train_files & test_files)\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500, \n",
    "        max_depth=10, \n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced', \n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_top[train_idx], y[train_idx])\n",
    "    y_pred = clf.predict(X_top[test_idx])\n",
    "    \n",
    "    acc = accuracy_score(y[test_idx], y_pred)\n",
    "    fold_scores.append(acc)\n",
    "    all_true.extend(y[test_idx])\n",
    "    all_pred.extend(y_pred)\n",
    "    \n",
    "    test_classes = sorted(np.unique(y[test_idx]))\n",
    "    print(f\"  Fold {fold_idx+1}: Acc={acc:.4f}, n_test={len(test_idx)}, file_overlap={overlap}, classes={test_classes}\")\n",
    "\n",
    "mean_acc = np.mean(fold_scores)\n",
    "std_acc = np.std(fold_scores)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"RandomForest + Top {top_k} Features - FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Mean Accuracy: {mean_acc:.4f} Â± {std_acc:.4f}\")\n",
    "print(f\"  Per-fold: {[round(s, 4) for s in fold_scores]}\")\n",
    "print()\n",
    "print(f\"  Baseline (CatBoost, all features): ~0.6566\")\n",
    "print(f\"  Improvement: {(mean_acc - 0.6566)*100:+.1f}%\")\n",
    "print()\n",
    "\n",
    "# Confusion matrix with original labels\n",
    "cm = confusion_matrix(all_true, all_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"Classes (encoded): {sorted(np.unique(y))}\")\n",
    "print(f\"Classes (original): {list(le.classes_)}\")\n",
    "print(cm)\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, target_names=[str(c) for c in le.classes_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3jfaqjvwe56",
   "metadata": {},
   "source": [
    "## Optimizing for the Actual Scoring Function\n",
    "\n",
    "The competition scoring is asymmetric:\n",
    "- **Underpredict (pred < true)**: 0 points (catastrophic!)\n",
    "- **Exact match**: 1 point\n",
    "- **Overpredict (pred > true)**: `true/pred` points (e.g., 0.5 for 1 step too high)\n",
    "\n",
    "Strategy: **When uncertain, predict higher to avoid zeros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7awods4u48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION WITH COMPETITION SCORING\n",
      "============================================================\n",
      "\n",
      "Strategy 1: Raw model predictions (no adjustment)\n",
      "--------------------------------------------------\n",
      "Competition Score: 99.00 / 137 = 0.7226 per sample\n",
      "  Exact matches:    94 ( 68.6%) â†’ 94.0 points\n",
      "  Underpredictions: 28 ( 20.4%) â†’ 0.0 points (LOST)\n",
      "  Overpredictions:  15 ( 10.9%) â†’ 5.0 points\n",
      "\n",
      "Strategy 2: Bias toward higher thresholds when uncertain\n",
      "--------------------------------------------------\n",
      "Competition Score: 92.00 / 137 = 0.6715 per sample\n",
      "  Exact matches:    82 ( 59.9%) â†’ 82.0 points\n",
      "  Underpredictions: 20 ( 14.6%) â†’ 0.0 points (LOST)\n",
      "  Overpredictions:  35 ( 25.5%) â†’ 10.0 points\n",
      "\n",
      "Strategy 3: Always predict 1 step higher (conservative)\n",
      "--------------------------------------------------\n",
      "Competition Score: 64.00 / 137 = 0.4672 per sample\n",
      "  Exact matches:    14 ( 10.2%) â†’ 14.0 points\n",
      "  Underpredictions: 14 ( 10.2%) â†’ 0.0 points (LOST)\n",
      "  Overpredictions: 109 ( 79.6%) â†’ 50.0 points\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "  Raw predictions:      0.7226 per sample (99.0 total)\n",
      "  Biased (uncertain):   0.6715 per sample (92.0 total)\n",
      "  Always +1 step:       0.4672 per sample (64.0 total)\n",
      "\n",
      "  Best strategy: Raw with 0.7226 per sample\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with ACTUAL competition scoring function\n",
    "import numpy as np\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate competition score.\n",
    "    - Underpredict (pred < true): 0 points\n",
    "    - Exact match: 1 point  \n",
    "    - Overpredict (pred > true): true/pred points\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    scores = np.zeros(len(y_true))\n",
    "    \n",
    "    # Exact match\n",
    "    exact = y_pred == y_true\n",
    "    scores[exact] = 1.0\n",
    "    \n",
    "    # Overpredict (partial credit)\n",
    "    over = y_pred > y_true\n",
    "    scores[over] = y_true[over] / y_pred[over]\n",
    "    \n",
    "    # Underpredict (zero points) - already 0\n",
    "    under = y_pred < y_true\n",
    "    # scores[under] = 0  # already initialized to 0\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def evaluate_with_competition_score(y_true, y_pred, y_pred_proba=None, threshold_classes=None):\n",
    "    \"\"\"Detailed evaluation with competition scoring.\"\"\"\n",
    "    scores = competition_score(y_true, y_pred)\n",
    "    \n",
    "    n = len(y_true)\n",
    "    exact = np.sum(y_pred == y_true)\n",
    "    under = np.sum(y_pred < y_true)\n",
    "    over = np.sum(y_pred > y_true)\n",
    "    \n",
    "    print(f\"Competition Score: {scores.sum():.2f} / {n} = {scores.mean():.4f} per sample\")\n",
    "    print(f\"  Exact matches:   {exact:3d} ({100*exact/n:5.1f}%) â†’ {exact:.1f} points\")\n",
    "    print(f\"  Underpredictions:{under:3d} ({100*under/n:5.1f}%) â†’ 0.0 points (LOST)\")\n",
    "    print(f\"  Overpredictions: {over:3d} ({100*over/n:5.1f}%) â†’ {scores[y_pred > y_true].sum():.1f} points\")\n",
    "    \n",
    "    return scores.mean(), scores.sum()\n",
    "\n",
    "# Test on our best model with actual scoring\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUATION WITH COMPETITION SCORING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Original predictions (no bias)\n",
    "print(\"Strategy 1: Raw model predictions (no adjustment)\")\n",
    "print(\"-\" * 50)\n",
    "score_raw, total_raw = evaluate_with_competition_score(\n",
    "    le.inverse_transform(all_true), \n",
    "    le.inverse_transform(all_pred)\n",
    ")\n",
    "print()\n",
    "\n",
    "# Now let's try biased predictions using predict_proba\n",
    "print(\"Strategy 2: Bias toward higher thresholds when uncertain\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Re-run with probability-based adjustment\n",
    "fold_scores_biased = []\n",
    "all_true_biased, all_pred_biased = [], []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(sgkf.split(X_top, y, groups)):\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500, max_depth=10, min_samples_leaf=2,\n",
    "        class_weight='balanced', random_state=42, n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_top[train_idx], y[train_idx])\n",
    "    \n",
    "    # Get probabilities\n",
    "    proba = clf.predict_proba(X_top[test_idx])\n",
    "    classes = clf.classes_\n",
    "    \n",
    "    # Biased prediction: if not confident, pick higher threshold\n",
    "    y_pred_biased = []\n",
    "    for p in proba:\n",
    "        max_prob = p.max()\n",
    "        max_class = classes[p.argmax()]\n",
    "        \n",
    "        if max_prob < 0.5:  # Not confident\n",
    "            # Pick the highest class with reasonable probability\n",
    "            # Weight toward higher thresholds\n",
    "            weighted_probs = p.copy()\n",
    "            for i, c in enumerate(classes):\n",
    "                # Boost probability of higher classes\n",
    "                weighted_probs[i] *= (1 + 0.3 * i)  # Higher index = higher threshold\n",
    "            y_pred_biased.append(classes[weighted_probs.argmax()])\n",
    "        else:\n",
    "            y_pred_biased.append(max_class)\n",
    "    \n",
    "    y_pred_biased = np.array(y_pred_biased)\n",
    "    all_true_biased.extend(y[test_idx])\n",
    "    all_pred_biased.extend(y_pred_biased)\n",
    "\n",
    "score_biased, total_biased = evaluate_with_competition_score(\n",
    "    le.inverse_transform(all_true_biased),\n",
    "    le.inverse_transform(all_pred_biased)\n",
    ")\n",
    "print()\n",
    "\n",
    "print(\"Strategy 3: Always predict 1 step higher (conservative)\")\n",
    "print(\"-\" * 50)\n",
    "# Shift all predictions up by 1 class\n",
    "all_pred_shifted = np.array(all_pred).copy()\n",
    "all_pred_shifted = np.minimum(all_pred_shifted + 1, len(le.classes_) - 1)  # Cap at max class\n",
    "\n",
    "score_shifted, total_shifted = evaluate_with_competition_score(\n",
    "    le.inverse_transform(all_true),\n",
    "    le.inverse_transform(all_pred_shifted)\n",
    ")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Raw predictions:      {score_raw:.4f} per sample ({total_raw:.1f} total)\")\n",
    "print(f\"  Biased (uncertain):   {score_biased:.4f} per sample ({total_biased:.1f} total)\")\n",
    "print(f\"  Always +1 step:       {score_shifted:.4f} per sample ({total_shifted:.1f} total)\")\n",
    "print()\n",
    "print(f\"  Best strategy: \", end=\"\")\n",
    "best = max([(score_raw, \"Raw\"), (score_biased, \"Biased\"), (score_shifted, \"+1 Step\")])\n",
    "print(f\"{best[1]} with {best[0]:.4f} per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "jgq7vwy59h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYZING UNDERPREDICTIONS (the 28 samples costing us points)\n",
      "============================================================\n",
      "\n",
      "Underprediction breakdown (pred < true):\n",
      "----------------------------------------\n",
      "  True=  2: predicted as [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)] (6 cases)\n",
      "  True=  4: predicted as [np.int64(1), np.int64(1), np.int64(1)] (3 cases)\n",
      "  True=  8: predicted as [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(2)] (9 cases)\n",
      "  True= 16: predicted as [np.int64(8), np.int64(8), np.int64(8), np.int64(8), np.int64(8), np.int64(8), np.int64(8), np.int64(8)] (8 cases)\n",
      "  True= 64: predicted as [np.int64(8), np.int64(8)] (2 cases)\n",
      "\n",
      "Pattern analysis:\n",
      "----------------------------------------\n",
      "  Underpredictions off by 1 step: 14\n",
      "  Underpredictions off by 2 steps: 7\n",
      "  Underpredictions off by 3+ steps: 7\n",
      "\n",
      "If we could fix just the '1 step off' underpredictions:\n",
      "  Potential gain: +14 points\n",
      "  New score: 113 / 137 = 0.8248\n",
      "\n",
      "Accuracy by true class:\n",
      "----------------------------------------\n",
      "  Class   1: Acc=92.6%, Under=0.0%, Over=7.4% (n=54)\n",
      "  Class   2: Acc=78.3%, Under=13.0%, Over=8.7% (n=46)\n",
      "  Class   4: Acc=0.0%, Under=50.0%, Over=50.0% (n=6)\n",
      "  Class   8: Acc=47.1%, Under=52.9%, Over=0.0% (n=17)\n",
      "  Class  16: Acc=0.0%, Under=66.7%, Over=33.3% (n=12)\n",
      "  Class  64: Acc=0.0%, Under=100.0%, Over=0.0% (n=2)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the underpredictions - where is the model failing?\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYZING UNDERPREDICTIONS (the 28 samples costing us points)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "y_true_orig = le.inverse_transform(all_true)\n",
    "y_pred_orig = le.inverse_transform(all_pred)\n",
    "\n",
    "under_mask = y_pred_orig < y_true_orig\n",
    "over_mask = y_pred_orig > y_true_orig\n",
    "exact_mask = y_pred_orig == y_true_orig\n",
    "\n",
    "print(\"Underprediction breakdown (pred < true):\")\n",
    "print(\"-\" * 40)\n",
    "under_true = y_true_orig[under_mask]\n",
    "under_pred = y_pred_orig[under_mask]\n",
    "\n",
    "for true_val in sorted(np.unique(under_true)):\n",
    "    mask = under_true == true_val\n",
    "    preds = under_pred[mask]\n",
    "    print(f\"  True={true_val:3d}: predicted as {sorted(preds)} ({len(preds)} cases)\")\n",
    "\n",
    "print()\n",
    "print(\"Pattern analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# How far off are the underpredictions?\n",
    "under_steps = np.log2(y_true_orig[under_mask]) - np.log2(y_pred_orig[under_mask])\n",
    "print(f\"  Underpredictions off by 1 step: {np.sum(under_steps == 1)}\")\n",
    "print(f\"  Underpredictions off by 2 steps: {np.sum(under_steps == 2)}\")\n",
    "print(f\"  Underpredictions off by 3+ steps: {np.sum(under_steps >= 3)}\")\n",
    "\n",
    "print()\n",
    "print(\"If we could fix just the '1 step off' underpredictions:\")\n",
    "one_step_under = np.sum(under_steps == 1)\n",
    "potential_gain = one_step_under  # Each becomes 1 point instead of 0\n",
    "print(f\"  Potential gain: +{potential_gain} points\")\n",
    "print(f\"  New score: {99 + potential_gain} / 137 = {(99 + potential_gain)/137:.4f}\")\n",
    "\n",
    "# What about class-specific accuracy?\n",
    "print()\n",
    "print(\"Accuracy by true class:\")\n",
    "print(\"-\" * 40)\n",
    "for cls in sorted(np.unique(y_true_orig)):\n",
    "    mask = y_true_orig == cls\n",
    "    cls_acc = np.mean(y_pred_orig[mask] == y_true_orig[mask])\n",
    "    cls_under = np.mean(y_pred_orig[mask] < y_true_orig[mask])\n",
    "    cls_over = np.mean(y_pred_orig[mask] > y_true_orig[mask])\n",
    "    n = np.sum(mask)\n",
    "    print(f\"  Class {cls:3d}: Acc={cls_acc:.1%}, Under={cls_under:.1%}, Over={cls_over:.1%} (n={n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57914913-f3e5-4d23-b128-50bbeada9aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
